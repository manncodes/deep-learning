# TODO

- READ: Mixture of Experts(MoE) model
- REVISE: LINALG
- READ: on external memory in transformers for longer context
- READ: Power scaling laws & Chinchilla paper
- CODE: Tiling for improving NN throughput
- READ: Optmization theory
- EXPLORE: HF Accelerate, FlexGEN, PyG
